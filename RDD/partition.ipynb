{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4eb8fe",
   "metadata": {},
   "source": [
    "# repartition()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f3731",
   "metadata": {},
   "source": [
    "1. repartition() is a transformation\n",
    "2. repartition() is used to increase or decrease the partitions.\n",
    "3. It re-distributes the data from all partitions which is full shuffle leading to very expensive operation when dealing with billions and trillions of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc2fd6",
   "metadata": {},
   "source": [
    "Before repartition <br>\n",
    "EX : <br>\n",
    "Node 1 = 1,2,3 <br>\n",
    "Node 2 = 4,5,6 <br>\n",
    "Node 3 = 7,8,9 <br>\n",
    "Node 4 = 10,11,12 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e728fe4",
   "metadata": {},
   "source": [
    "After repartition = 2<br>\n",
    "EX : <br>\n",
    "Node 1 = 7,2,11,1,8,5,12 <br>\n",
    "Node 2 = 4,3,9,6,10 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f4ca6",
   "metadata": {},
   "source": [
    "# coalesce()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7f858",
   "metadata": {},
   "source": [
    "1. coalesce() is a transformation.\n",
    "2. coalesce() is only used to reduce the number of partitions.\n",
    "3. This is improved version of repartition() where the movement of the data across the partitions is lower using coalesce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc8687",
   "metadata": {},
   "source": [
    "Before coalesce <br>\n",
    "EX : <br>\n",
    "Node 1 = 1,2,3 <br>\n",
    "Node 2 = 4,5,6 <br>\n",
    "Node 3 = 7,8,9 <br>\n",
    "Node 4 = 10,11,12 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d8d26b",
   "metadata": {},
   "source": [
    "After coalesce = 2 <br>\n",
    "EX : <br>\n",
    "Node 1 = 1,2,3 + (10,11,12) <br>\n",
    "Node 3 = 7,8,9 + (4,5,6)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bb7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setAppName('Read File')\n",
    "sc = SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d37daa",
   "metadata": {},
   "source": [
    "## repartition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f618821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('D:\\Sample.txt')\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1861d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.repartition(5)\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ac67f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is Line 1',\n",
       " 'This is Line 2',\n",
       " 'Hello Pyspark.',\n",
       " 'I am learning Pyspark.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c1b901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 1),\n",
       " ('is', 1),\n",
       " ('Line', 1),\n",
       " ('1', 1),\n",
       " ('This', 1),\n",
       " ('is', 1),\n",
       " ('Line', 1),\n",
       " ('2', 1),\n",
       " ('Hello', 1),\n",
       " ('Pyspark.', 1),\n",
       " ('I', 1),\n",
       " ('am', 1),\n",
       " ('learning', 1),\n",
       " ('Pyspark.', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd.flatMap(lambda x: x.split())\n",
    "rdd3 = rdd2.map(lambda x: (x,1))\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "868a060a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('D:\\Sample.txt')\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bee9735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd.repartition(5)\n",
    "rdd2 = rdd.flatMap(lambda x: x.split())\n",
    "rdd3 = rdd2.map(lambda x: (x,1))\n",
    "rdd3.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00696d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4 = rdd3.coalesce(2)\n",
    "rdd4.getNumPartitions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
