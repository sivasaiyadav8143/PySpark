{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5c1ab8",
   "metadata": {},
   "source": [
    "1. It create groups based on keys in RDD\n",
    "2. It is a transformation operation that performs shuffling of data\n",
    "3. This shuffling makes this transformation as a wider transformation.\n",
    "4. Data must be in (Key,value) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467db967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setAppName('groupBykey')\n",
    "sc = SparkContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1544853b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Pyspark.',\n",
       " 'I am learning Pyspark.',\n",
       " 'This is Line 1',\n",
       " 'This is Line 2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('D:\\Sample.txt')\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a48428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 1),\n",
       " ('Pyspark.', 1),\n",
       " ('I', 1),\n",
       " ('am', 1),\n",
       " ('learning', 1),\n",
       " ('Pyspark.', 1),\n",
       " ('This', 1),\n",
       " ('is', 1),\n",
       " ('Line', 1),\n",
       " ('1', 1),\n",
       " ('This', 1),\n",
       " ('is', 1),\n",
       " ('Line', 1),\n",
       " ('2', 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_val = rdd.flatMap(lambda x : [(i,1) for i in x.split()])\n",
    "key_val.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a7c3bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', <pyspark.resultiterable.ResultIterable at 0x20523fe99d0>),\n",
       " ('Pyspark.', <pyspark.resultiterable.ResultIterable at 0x20523f5e610>),\n",
       " ('am', <pyspark.resultiterable.ResultIterable at 0x20523f5e400>),\n",
       " ('learning', <pyspark.resultiterable.ResultIterable at 0x20523f5e7f0>),\n",
       " ('is', <pyspark.resultiterable.ResultIterable at 0x20523f5e070>),\n",
       " ('Line', <pyspark.resultiterable.ResultIterable at 0x20523f5e310>),\n",
       " ('1', <pyspark.resultiterable.ResultIterable at 0x20523f5e220>),\n",
       " ('I', <pyspark.resultiterable.ResultIterable at 0x20523f5e520>),\n",
       " ('This', <pyspark.resultiterable.ResultIterable at 0x20523f5e3a0>),\n",
       " ('2', <pyspark.resultiterable.ResultIterable at 0x20523fad6d0>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_val.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ad6880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello , 1\n",
      "Pyspark. , 2\n",
      "am , 1\n",
      "learning , 1\n",
      "is , 2\n",
      "Line , 2\n",
      "1 , 1\n",
      "I , 1\n",
      "This , 2\n",
      "2 , 1\n"
     ]
    }
   ],
   "source": [
    "for i in key_val.groupByKey().collect():\n",
    "    print(i[0],\",\",sum(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a79914c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', [1]),\n",
       " ('Pyspark.', [1, 1]),\n",
       " ('am', [1]),\n",
       " ('learning', [1]),\n",
       " ('is', [1, 1]),\n",
       " ('Line', [1, 1]),\n",
       " ('1', [1]),\n",
       " ('I', [1]),\n",
       " ('This', [1, 1]),\n",
       " ('2', [1])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_val.groupByKey().mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a90633c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 1),\n",
       " ('Pyspark.', 2),\n",
       " ('am', 1),\n",
       " ('learning', 1),\n",
       " ('is', 2),\n",
       " ('Line', 2),\n",
       " ('1', 1),\n",
       " ('I', 1),\n",
       " ('This', 2),\n",
       " ('2', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_val.groupByKey().mapValues(sum).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "895982ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_val.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc6232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
